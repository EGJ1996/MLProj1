{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from myhelpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"datasets/train.csv\"\n",
    "yb, input_data, ids = load_csv_data(data_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split according to jet_number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the number of data of PRI_jet_num = 0, 1, 2, 3\n",
    "def class_allocation(input_data, yb, ids):\n",
    "    num_0 = 0\n",
    "    num_1 = 0\n",
    "    num_2 = 0\n",
    "    num_3 = 0 \n",
    "    for j in range(input_data.shape[0]):\n",
    "        if input_data[j,22] == 0:\n",
    "            num_0 = num_0 + 1\n",
    "        elif input_data[j,22] == 1:\n",
    "            num_1 = num_1 + 1\n",
    "        elif input_data[j,22] == 2:\n",
    "            num_2 = num_2 + 1\n",
    "        elif input_data[j,22] == 3:\n",
    "            num_3 = num_3 + 1\n",
    "\n",
    "    # initializing arrays for different PRI_jet_num\n",
    "\n",
    "    size = (num_0, input_data.shape[1])\n",
    "    jet_num_0 = np.zeros(size)\n",
    "    ids_0 = np.zeros(num_0)\n",
    "    y0 = np.zeros(num_0)\n",
    "\n",
    "    size = (num_1, input_data.shape[1])\n",
    "    jet_num_1 = np.zeros(size)\n",
    "    ids_1 = np.zeros(num_1)\n",
    "    y1 = np.zeros(num_1)\n",
    "    \n",
    "    size = (num_2, input_data.shape[1])\n",
    "    jet_num_2 = np.zeros(size)\n",
    "    ids_2 = np.zeros(num_2)\n",
    "    y2 = np.zeros(num_2)\n",
    "    \n",
    "    size = (num_3, input_data.shape[1])\n",
    "    jet_num_3 = np.zeros(size)\n",
    "    ids_3 = np.zeros(num_3)\n",
    "    y3 = np.zeros(num_3)\n",
    "    \n",
    "    # allocating input_data to different classes due to their PRI_jet_num value\n",
    "    i_0, i_1, i_2, i_3 = 0, 0, 0, 0\n",
    "\n",
    "\n",
    "    for i in range(input_data.shape[0]):\n",
    "        if input_data[i,22] == 0:\n",
    "            jet_num_0[i_0,:] = input_data[i,:]\n",
    "            ids_0[i_0] = i\n",
    "            y0[i_0] = yb[i]\n",
    "            i_0 = i_0 + 1\n",
    "            \n",
    "        elif input_data[i,22] == 1:\n",
    "            jet_num_1[i_1,:] = input_data[i,:]\n",
    "            ids_1[i_1] = i\n",
    "            y1[i_1] = yb[i]\n",
    "            i_1 = i_1 + 1\n",
    "            \n",
    "        elif input_data[i,22] == 2:\n",
    "            jet_num_2[i_2,:] = input_data[i,:]\n",
    "            ids_2[i_2] = int(i)\n",
    "            y2[i_2] = yb[i]\n",
    "            i_2 = i_2 + 1\n",
    "            \n",
    "        elif input_data[i,22] == 3:\n",
    "            jet_num_3[i_3,:] = input_data[i,:]\n",
    "            ids_3[i_3] = int(i)\n",
    "            y3[i_3] = yb[i]\n",
    "            i_3 = i_3 + 1\n",
    "            \n",
    "    ids_0 = ids_0.astype(int)\n",
    "    ids_1 = ids_1.astype(int)\n",
    "    ids_2 = ids_2.astype(int)\n",
    "    ids_3 = ids_3.astype(int)\n",
    "    \n",
    "    return jet_num_0, y0, ids_0, jet_num_1, y1, ids_1, jet_num_2, y2, ids_2, jet_num_3, y3, ids_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet0_in, yb0, ids0, jet1_in, yb1, ids1, jet2_in, yb2, ids2, jet3_in, yb3, ids3 = class_allocation(input_data, yb, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 30) (77544, 30) (50379, 30) (22164, 30)\n"
     ]
    }
   ],
   "source": [
    "print(jet0_in.shape, jet1_in.shape, jet2_in.shape, jet3_in.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the feature \"pri_jet_num\" since we've already taken into account its contribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet0_in = np.delete(jet0_in,22,1)\n",
    "jet1_in = np.delete(jet1_in,22,1)\n",
    "jet2_in = np.delete(jet2_in,22,1)\n",
    "jet3_in = np.delete(jet3_in,22,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 29) (77544, 29) (50379, 29) (22164, 29)\n"
     ]
    }
   ],
   "source": [
    "print(jet0_in.shape, jet1_in.shape, jet2_in.shape, jet3_in.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and standardizing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We clean the four matrices from features with a standard deviation of 0. These features are considered non-measured.\n",
    "\n",
    "def remove_useless_cols(matrix):\n",
    "    std_cols = np.std(matrix, axis=0)\n",
    "    num_rem = 0\n",
    "    for col in reversed(range(matrix.shape[1])):\n",
    "        if std_cols[col] == 0:\n",
    "            num_rem = num_rem + 1\n",
    "    #removed_cols = np.zeros(num_rem)\n",
    "    #k = 0        \n",
    "    for col in reversed(range(matrix.shape[1])):\n",
    "        if std_cols[col] == 0:\n",
    "            matrix = np.delete(matrix,col,1)\n",
    "            #removed_cols[k] = col\n",
    "            #k = k + 1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet0_in = remove_useless_cols(jet0_in)\n",
    "jet1_in = remove_useless_cols(jet1_in)\n",
    "jet2_in = remove_useless_cols(jet2_in)\n",
    "jet3_in = remove_useless_cols(jet3_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 18) (77544, 22) (50379, 29) (22164, 29)\n"
     ]
    }
   ],
   "source": [
    "print(jet0_in.shape, jet1_in.shape, jet2_in.shape, jet3_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the invalid values -999 such that they are 0 after the standardization\n",
    "\n",
    "def clean_data(matrix):\n",
    "    cleansubx = matrix\n",
    "    cleansubx[np.where(cleansubx == -999)] = 0\n",
    "    means_by_columns = np.mean(cleansubx, axis=0)\n",
    "    for i in range(matrix.shape[1]):\n",
    "        matrix[:,np.where(matrix[:,i]==-999)] = means_by_columns[i]\n",
    "    return matrix\n",
    "\n",
    "def clean_and_standardize(matrix):\n",
    "    matrix = clean_data(matrix)\n",
    "    matrix = standardize(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet0_clean = clean_and_standardize(jet0_in)\n",
    "jet1_clean = clean_and_standardize(jet1_in)\n",
    "jet2_clean = clean_and_standardize(jet2_in)\n",
    "jet3_clean = clean_and_standardize(jet3_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 18) (77544, 22) (50379, 29) (22164, 29)\n"
     ]
    }
   ],
   "source": [
    "print(jet0_clean.shape, jet1_clean.shape, jet2_clean.shape, jet3_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate correlations in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation matrix.\n",
    "\n",
    "def plot_corr(matrix):\n",
    "    cols = matrix.shape[1]\n",
    "    cor_matrix = np.corrcoef(matrix.T)\n",
    "    plt.figure(1, figsize=(12,12))\n",
    "    plt.matshow(np.abs(cor_matrix),1)\n",
    "    plt.xticks(range(cols), range(cols))\n",
    "    plt.yticks(range(cols), range(cols))\n",
    "    plt.colorbar()\n",
    "    #plt.savefig('correlation_matrix'+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the correlated columns \n",
    "\n",
    "def get_correlations(matrix, bound):\n",
    "    high_corr = []\n",
    "    cor_matrix = np.corrcoef(matrix.T)\n",
    "    for i in range(cor_matrix.shape[0]):\n",
    "        for j in range(i+1,cor_matrix.shape[1]):\n",
    "            if cor_matrix[i,j] > bound:\n",
    "                high_corr.append((i,j))\n",
    "    return high_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 5), (6, 9)]\n",
      "[(3, 6), (3, 18), (3, 21), (6, 18), (6, 21), (18, 21)]\n",
      "[(3, 9), (4, 5), (9, 21), (9, 22), (9, 28), (21, 28), (22, 28)]\n",
      "[(9, 21), (9, 22), (9, 28), (21, 22), (21, 28), (22, 28), (25, 28)]\n"
     ]
    }
   ],
   "source": [
    "bound = 0.8\n",
    "print(get_correlations(jet0_clean, bound))\n",
    "print(get_correlations(jet1_clean, bound))\n",
    "print(get_correlations(jet2_clean, bound))\n",
    "print(get_correlations(jet3_clean, bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size jet0 : (99913, 16)\n",
      "Size jet1 : (77544, 19)\n",
      "Size jet2 : (50379, 24)\n",
      "Size jet3 : (22164, 26)\n"
     ]
    }
   ],
   "source": [
    "# Remove the selected columns\n",
    "\n",
    "jet0 = np.delete(jet0_clean,[5,9],1)\n",
    "jet1 = np.delete(jet1_clean,[6, 18, 21],1)\n",
    "jet2 = np.delete(jet2_clean,[9, 5, 21, 22, 28],1)\n",
    "jet3 = np.delete(jet3_clean,[21, 22, 28],1)\n",
    "\n",
    "print('Size jet0 : {s}'.format(s=jet0.shape))\n",
    "print('Size jet1 : {s}'.format(s=jet1.shape))\n",
    "print('Size jet2 : {s}'.format(s=jet2.shape))\n",
    "print('Size jet3 : {s}'.format(s=jet3.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING POLYNOMIAL BASIS\n",
    "\n",
    "# Function that builds a polynomial basis of the chosen degree for a column \n",
    "def build_poly_col(x, degree):\n",
    "    \"\"\"polynomial basis functions for input column x, for j=1 up to j=degree.\"\"\"\n",
    "    \n",
    "    y = x        \n",
    "    for n in range(2,degree+1):\n",
    "        x = np.c_[x, np.power(y,n)]\n",
    "            \n",
    "    return x\n",
    "\n",
    "# Function that builds a polynomial basis for the data (each column has the same degree)\n",
    "def build_poly(data, degree):\n",
    "    \"\"\"polynomial basis for input data up to the chosen degree in each column\"\"\"\n",
    "    \n",
    "    X = np.c_[np.ones(data.shape[0])]\n",
    "    for j in range(data.shape[1]):\n",
    "        x_col = build_poly_col(data[:,j], degree)\n",
    "        X = np.c_[X, x_col]\n",
    "        \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTING THE TRAINING SET FOR CROSS VALIDAITON\n",
    "\n",
    "# Functions to build the indices and split the data to perform cross validation\n",
    "\n",
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    \n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "\n",
    "def split_dataset(y, x, k, k_indices):\n",
    "    \"\"\"Returns the matrices and vectors Test and Train used in a k-fold cross validation\"\"\"\n",
    "    \n",
    "    # get k'th subgroup in test, others in train.\n",
    "    X_test = x[k_indices[k]]\n",
    "    y_test = y[k_indices[k]]\n",
    "    X_train = np.delete(x,k_indices[k],0)\n",
    "    y_train = np.delete(y,k_indices[k])\n",
    "    \n",
    "    return X_test, y_test, X_train, y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search Ridge regression.\n",
    "We look for the best lambda and polynomial degree for each group trough cross validation, saving the weights too. The tool to evaluate the model is the accuracy but we compute the rmse too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_deg_lam(yb, data, kfolds, degree, lambda_):\n",
    "    \"\"\"Builds a polynomial basis according to the chosen degree and solves the ridge regression\n",
    "        with the normal equations for lambda_, performing a k-fold cross validation \n",
    "        to compute the rmse and the weights\"\"\"\n",
    "    \n",
    "    rmse_train=[]\n",
    "    rmse_test=[]\n",
    "    seed = 3\n",
    "\n",
    "    # Build indices to split data\n",
    "    k_indices = build_k_indices(yb, kfolds, seed)\n",
    "\n",
    "    rmse_tr_k = []\n",
    "    rmse_te_k = []\n",
    "    w_ridge_k = []\n",
    "    accuracy_k = []\n",
    "        \n",
    "    # Build X matrix\n",
    "    data1 = build_poly(data, degree)\n",
    "    \n",
    "    # Loop over the folds\n",
    "    for k in range(kfolds):\n",
    "        \n",
    "        data_test, y_test, data_train, y_train = split_dataset(yb, data1, k, k_indices)   \n",
    "        \n",
    "        # Train the model\n",
    "        w_k, mse_k = ridge_regression(y_train, data_train, lambda_)\n",
    "        rmse_test = np.sqrt(2*compute_mse(y_test, data_test, w_k))\n",
    "            \n",
    "        # Do the prediction on the current test set and compute accuracy\n",
    "        ypred = predict_labels(w_k, data_test)\n",
    "        acc_k = compute_accuracy(ypred, y_test)\n",
    "            \n",
    "        # Store rmse, weights and accuracy\n",
    "        rmse_tr_k.append(np.sqrt(2*mse_k))\n",
    "        rmse_te_k.append(rmse_test)\n",
    "        w_ridge_k.append(w_k)\n",
    "        accuracy_k.append(acc_k)\n",
    "        \n",
    "    # Compute the means over the folds\n",
    "    rmse_tr = np.mean(rmse_tr_k)\n",
    "    rmse_te = np.mean(rmse_te_k)\n",
    "    w_ridge = np.mean(w_ridge_k, axis=0)\n",
    "    accuracy = np.mean(accuracy_k)\n",
    "        \n",
    "\n",
    "    return rmse_tr, rmse_te, w_ridge, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the error and accuracy plots\n",
    "\n",
    "def ridge_lambda_vis(lambdas, rmse_tr, rmse_te, std_train, std_test, acc, deg):\n",
    "    \"\"\"visualization of the curves of rmse_tr and rmse_te, and of the accuracy\"\"\"\n",
    "    \n",
    "    plt.figure(4, figsize=(16,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.semilogx(lambdas, rmse_tr, marker=\".\", color='b', label='Train error')\n",
    "    plt.semilogx(lambdas, rmse_te, marker=\".\", color='r', label='Test error')\n",
    "    #plt.errorbar(np.log10(lambdas), rmse_tr, std_train, label='Train error')\n",
    "    #plt.errorbar(np.log10(lambdas), rmse_te, std_test, label='Test error')\n",
    "    #plt.plot(lambdas, rmse_tr, marker=\".\", color='b', label='Train error')\n",
    "    #plt.plot(lambdas, rmse_te, marker=\".\", color='r', label='Test error')\n",
    "    plt.xlabel(\"Lambda\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE ridge regression with degree {ddd}\".format(ddd=deg))\n",
    "    plt.legend(loc=2)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.semilogx(lambdas, acc,  marker=\".\", color='b', label='Accuracy')\n",
    "    #plt.plot(lambdas, acc,  marker=\".\", color='b', label='Accuracy')\n",
    "    plt.xlabel(\"Lambda\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"ACCURACY ridge regression with degree {ddd}\".format(ddd=deg))\n",
    "    plt.legend(loc=1)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying with a fixed degree \n",
    "lambdas = 0.05\n",
    "deg = 6\n",
    "rmse_tr0, rmse_te0, weight0, acc0 = ridge_deg_lam(yb0, jet0, 4, deg, lambdas)\n",
    "#ridge_lambda_vis(lambdas, rmse_tr0, rmse_te0, _, _, acc0, deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_te0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing grid search for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "def grid_search_ridge(y, tx, kfolds, deg_grid, lam_grid):\n",
    "    \"\"\"Performs a grid search over degrees and lambdas to find the best parameters for the model trained over tx\n",
    "       Returns the optimal lambda, the optimal degree and the optimal weights obtained with a kfolds cross validation\n",
    "       (The tool to evaluate and compare models is the accuracy)\"\"\"\n",
    "    \n",
    "    losses = np.zeros((len(deg_grid),len(lam_grid)))\n",
    "    accuracies = np.zeros((len(deg_grid),len(lam_grid)))\n",
    "    acc_old = -1\n",
    "    \n",
    "    # Perform a grid search\n",
    "    for i, deg in enumerate(deg_grid):\n",
    "        for j, lam in enumerate(lam_grid):  \n",
    "            \n",
    "            rmse_train, rmse_test, w_ridge, acc = ridge_deg_lam(y, tx, kfolds, deg, lam)\n",
    "            \n",
    "            losses[i,j] = rmse_test\n",
    "            accuracies[i,j] = acc\n",
    "            \n",
    "            if acc > acc_old:\n",
    "                weight_opt = w_ridge\n",
    "                deg_opt_acc = deg     # it' better to select the optimal parameters in this way (not with get_best()) because if\n",
    "                lam_opt_acc = lam     # the accuracy is the same with different parameters, we may get different sizes of the \n",
    "                max_accuracy = acc    # weights vector and the matrix with the polynomial basis\n",
    "            \n",
    "            acc_old = acc            \n",
    "        \n",
    "    # Get best parameters\n",
    "    min_rmse_test, deg_opt_err, lam_opt_err = get_best_rmse(lambdas_grid, degree_grid, losses)  \n",
    "    #max_accuracy, deg_opt_acc, lam_opt_acc = get_best_accuracy(lam_grid, deg_grid, accuracies)\n",
    "    \n",
    "    return min_rmse_test, deg_opt_err, lam_opt_err, max_accuracy, deg_opt_acc, lam_opt_acc, weight_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Test RMSE: 0.737804793602948\n",
      "Optimal degree: 1\n",
      "Optimal lambda: 0.0007196856730011522\n",
      "Maximum accuracy: 0.7950996877251981\n",
      "Optimal degree: 11\n",
      "Optimal lambda: 7.9060432109077015\n",
      "Weights shape: (177,)\n"
     ]
    }
   ],
   "source": [
    "# Define the range for the parameters \n",
    "degree_grid = range(1,12)\n",
    "lambdas_grid = np.logspace(-7,2,50)\n",
    "kfolds = 4\n",
    "\n",
    "# n_columns jet0 = 16\n",
    "rmse0, degerr0, lamerr0, acc0, degacc0, lamacc0, weights0 = grid_search_ridge(yb0, jet0, kfolds, degree_grid, lambdas_grid)\n",
    "\n",
    "print('Minimum Test RMSE: {rmse}'.format(rmse=rmse0))\n",
    "print('Optimal degree: {d}'.format(d=degerr0))\n",
    "print('Optimal lambda: {l}'.format(l=lamerr0))\n",
    "\n",
    "print('Maximum accuracy: {acc}'.format(acc=acc0))\n",
    "print('Optimal degree: {d}'.format(d=degacc0))\n",
    "print('Optimal lambda: {l}'.format(l=lamacc0))\n",
    "print('Weights shape: {w}'.format(w=weights0.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Test RMSE: 0.8080010143389709\n",
      "Optimal degree: 5\n",
      "Optimal lambda: 0.03237457542817647\n",
      "Maximum accuracy: 0.8033761477354793\n",
      "Optimal degree: 11\n",
      "Optimal lambda: 0.00047148663634573947\n",
      "Weights shape: (210,)\n"
     ]
    }
   ],
   "source": [
    "# n_columns jet1 = 19\n",
    "rmse1, degerr1, lamerr1, acc1, degacc1, lamacc1, weights1 = grid_search_ridge(yb1, jet1, kfolds, degree_grid, lambdas_grid)\n",
    "\n",
    "print('Minimum Test RMSE: {rmse}'.format(rmse=rmse1))\n",
    "print('Optimal degree: {d}'.format(d=degerr1))\n",
    "print('Optimal lambda: {l}'.format(l=lamerr1))\n",
    "\n",
    "print('Maximum accuracy: {acc}'.format(acc=acc1))\n",
    "print('Optimal degree: {d}'.format(d=degacc1))\n",
    "print('Optimal lambda: {l}'.format(l=lamacc1))\n",
    "print('Weights shape: {w}'.format(w=weights1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Test RMSE: 0.7959194689173034\n",
      "Optimal degree: 4\n",
      "Optimal lambda: 0.021209508879201925\n",
      "Maximum accuracy: 0.829958710497062\n",
      "Optimal degree: 11\n",
      "Optimal lambda: 0.0025595479226995384\n",
      "Weights shape: (265,)\n"
     ]
    }
   ],
   "source": [
    "# n_columns jet2 = 24\n",
    "rmse2, degerr2, lamerr2, acc2, degacc2, lamacc2, weights2 = grid_search_ridge(yb2, jet2, kfolds, degree_grid, lambdas_grid)\n",
    "\n",
    "print('Minimum Test RMSE: {rmse}'.format(rmse=rmse2))\n",
    "print('Optimal degree: {d}'.format(d=degerr2))\n",
    "print('Optimal lambda: {l}'.format(l=lamerr2))\n",
    "\n",
    "print('Maximum accuracy: {acc}'.format(acc=acc2))\n",
    "print('Optimal degree: {d}'.format(d=degacc2))\n",
    "print('Optimal lambda: {l}'.format(l=lamacc2))\n",
    "print('Weights shape: {w}'.format(w=weights2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Test RMSE: 0.7987655327075097\n",
      "Optimal degree: 4\n",
      "Optimal lambda: 0.0025595479226995384\n",
      "Maximum accuracy: 0.8290019852012271\n",
      "Optimal degree: 11\n",
      "Optimal lambda: 0.00047148663634573947\n",
      "Weights shape: (287,)\n"
     ]
    }
   ],
   "source": [
    "# n_columns jet3 = 26\n",
    "rmse3, degerr3, lamerr3, acc3, degacc3, lamacc3, weights3 = grid_search_ridge(yb3, jet3, kfolds, degree_grid, lambdas_grid)\n",
    "\n",
    "print('Minimum Test RMSE: {rmse}'.format(rmse=rmse3))\n",
    "print('Optimal degree: {d}'.format(d=degerr3))\n",
    "print('Optimal lambda: {l}'.format(l=lamerr3))\n",
    "\n",
    "print('Maximum accuracy: {acc}'.format(acc=acc3))\n",
    "print('Optimal degree: {d}'.format(d=degacc3))\n",
    "print('Optimal lambda: {l}'.format(l=lamacc3))\n",
    "print('Weights shape: {w}'.format(w=weights3.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, split, clean, build test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"datasets/test.csv\"\n",
    "yb_test, input_data_test, ids_test = load_csv_data(data_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227458, 30) (175338, 30) (114648, 30) (50794, 30)\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "\n",
    "test0_in, test_yb0, test_ids0, test1_in, test_yb1, test_ids1, test2_in, test_yb2, test_ids2, test3_in, test_yb3, test_ids3 = class_allocation(input_data_test, yb_test, ids_test)\n",
    "\n",
    "print(test0_in.shape, test1_in.shape, test2_in.shape, test3_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350001 350002 350003 350004 350005 350006 350007 350008 350009 350010\n",
      " 350011 350012 350013 350014 350015 350016 350017 350018 350019]\n",
      "[ 0  2  3  5  8 11 12 14 15 16]\n",
      "[ 1  6 10 18 20 23 26 31 33 34]\n",
      "[ 7  9 13 21 24 43 47 53 62 64]\n",
      "[  4  22  25  28  35  71  85  99 118 131]\n",
      "[ 0  2  3  5  8 11 12 14 15 16]\n"
     ]
    }
   ],
   "source": [
    "print(ids_test[1:20])\n",
    "print(test_ids0[:10])\n",
    "print(test_ids1[:10])\n",
    "print(test_ids2[:10])\n",
    "print(test_ids3[:10])\n",
    "print( test_ids0[:10].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227458, 18) (175338, 22) (114648, 29) (50794, 29)\n"
     ]
    }
   ],
   "source": [
    "# We clean the four matrices from features with a standard deviation of 0. These features are considered non-measured.\n",
    "\n",
    "test0_in = remove_useless_cols(test0_in)\n",
    "test1_in = remove_useless_cols(test1_in)\n",
    "test2_in = remove_useless_cols(test2_in)\n",
    "test3_in = remove_useless_cols(test3_in)\n",
    "\n",
    "print(test0_in.shape, test1_in.shape, test2_in.shape, test3_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the invalid values -999 and standardize\n",
    "test0_clean = clean_and_standardize(test0_in)\n",
    "test1_clean = clean_and_standardize(test1_in)\n",
    "test2_clean = clean_and_standardize(test2_in)\n",
    "test3_clean = clean_and_standardize(test3_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate correlated columns\n",
    "\n",
    "test0 = np.delete(test0_clean,[5,9],1)\n",
    "test1 = np.delete(test1_clean,[6, 18, 21],1)\n",
    "test2 = np.delete(test2_clean,[9, 5, 21, 22, 28],1)\n",
    "test3 = np.delete(test3_clean,[21, 22, 28],1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size jet0 : (227458, 177), size weights0 : (177,)\n",
      "Size jet1 : (175338, 210), size weights1 : (210,)\n",
      "Size jet2 : (114648, 265), size weights2 : (265,)\n",
      "Size jet3 : (50794, 287), size weights3 : (287,)\n"
     ]
    }
   ],
   "source": [
    "# Build the polynomial basis according to the groups\n",
    "test0fin = build_poly(test0, degacc0)\n",
    "test1fin = build_poly(test1, degacc1)\n",
    "test2fin = build_poly(test2, degacc2)\n",
    "test3fin = build_poly(test3, degacc3)\n",
    "\n",
    "print('Size jet0 : {s}, size weights0 : {w}'.format(s=test0fin.shape, w=weights0.shape))\n",
    "print('Size jet1 : {s}, size weights1 : {w}'.format(s=test1fin.shape, w=weights1.shape))\n",
    "print('Size jet2 : {s}, size weights2 : {w}'.format(s=test2fin.shape, w=weights2.shape))\n",
    "print('Size jet3 : {s}, size weights3 : {w}'.format(s=test3fin.shape, w=weights3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  3  5  8 11]\n"
     ]
    }
   ],
   "source": [
    "ypred0 = predict_labels(weights0, test0fin)\n",
    "ypred1 = predict_labels(weights1, test1fin)\n",
    "ypred2 = predict_labels(weights2, test2fin)\n",
    "ypred3 = predict_labels(weights3, test3fin)\n",
    "\n",
    "create_submission(ypred0, test_ids0, ypred1, test_ids1, ypred2, test_ids2, ypred3, test_ids3, ids_test, 'ridge_splitted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
